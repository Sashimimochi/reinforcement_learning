{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 盤面\n",
    "0~9の配列にXなら1,空なら0,◯なら−1を入れます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMPTY=0\n",
    "PLAYER_X=1\n",
    "PLAYER_O=-1\n",
    "MARKS={PLAYER_X:\"X\",PLAYER_O:\"O\",EMPTY:\" \"}\n",
    "DRAW=2\n",
    "\n",
    "class TTTBoard:\n",
    "\n",
    "    def __init__(self,board=None):\n",
    "        if board==None:\n",
    "            self.board = []\n",
    "            for i in range(9):self.board.append(EMPTY)\n",
    "        else:\n",
    "            self.board=board\n",
    "        self.winner=None\n",
    "\n",
    "    def get_possible_pos(self):\n",
    "        pos=[]\n",
    "        for i in range(9):\n",
    "            if self.board[i]==EMPTY:\n",
    "                pos.append(i)\n",
    "        return pos\n",
    "\n",
    "    def print_board(self):\n",
    "        tempboard=[]\n",
    "        for i in self.board:\n",
    "            tempboard.append(MARKS[i])\n",
    "        row = ' {} | {} | {} '\n",
    "        hr = '\\n-----------\\n'\n",
    "        print((row + hr + row + hr + row).format(*tempboard))\n",
    "\n",
    "\n",
    "\n",
    "    def check_winner(self):\n",
    "        win_cond = ((1,2,3),(4,5,6),(7,8,9),(1,4,7),(2,5,8),(3,6,9),(1,5,9),(3,5,7))\n",
    "        for each in win_cond:\n",
    "            if self.board[each[0]-1] == self.board[each[1]-1]  == self.board[each[2]-1]:\n",
    "                if self.board[each[0]-1]!=EMPTY:\n",
    "                    self.winner=self.board[each[0]-1]\n",
    "                    return self.winner\n",
    "        return None\n",
    "\n",
    "    def check_draw(self):\n",
    "        if len(self.get_possible_pos())==0 and self.winner is None:\n",
    "            self.winner=DRAW\n",
    "            return DRAW\n",
    "        return None\n",
    "\n",
    "    def move(self,pos,player):\n",
    "        if self.board[pos]== EMPTY:\n",
    "            self.board[pos]=player\n",
    "        else:\n",
    "            self.winner=-1*player\n",
    "        self.check_winner()\n",
    "        self.check_draw()\n",
    "\n",
    "    def clone(self):\n",
    "        return TTTBoard(self.board.copy())\n",
    "\n",
    "    def switch_player(self):\n",
    "        if self.player_turn == self.player_x:\n",
    "            self.player_turn=self.player_o\n",
    "        else:\n",
    "            self.player_turn=self.player_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ゲームの進行役\n",
    "ObserverとMediatorをモデル化する。\n",
    "これでPlayerが直接盤面を操作することなく、ターン進行・勝敗判定・表示の管理などを行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TTT_GameOrganizer:\n",
    "\n",
    "    act_turn=0\n",
    "    winner=None\n",
    "\n",
    "    def __init__(self,px,po,nplay=1,showBoard=True,showResult=True,stat=100):\n",
    "        self.player_x=px\n",
    "        self.player_o=po\n",
    "        self.nwon={px.myturn:0,po.myturn:0,DRAW:0}\n",
    "        self.nplay=nplay\n",
    "        self.players=(self.player_x,self.player_o)\n",
    "        self.board=None\n",
    "        self.disp=showBoard\n",
    "        self.showResult=showResult\n",
    "        self.player_turn=self.players[random.randrange(2)]\n",
    "        self.nplayed=0\n",
    "        self.stat=stat\n",
    "\n",
    "    def progress(self):\n",
    "        while self.nplayed<self.nplay:\n",
    "            self.board=TTTBoard()\n",
    "            while self.board.winner==None:\n",
    "                if self.disp:print(\"Turn is \"+self.player_turn.name)\n",
    "                act=self.player_turn.act(self.board)\n",
    "                self.board.move(act,self.player_turn.myturn)\n",
    "                if self.disp:self.board.print_board()\n",
    "\n",
    "                if self.board.winner != None:\n",
    "                    # notice every player that game ends\n",
    "                    for i in self.players:\n",
    "                        i.getGameResult(self.board) \n",
    "                    if self.board.winner == DRAW:\n",
    "                        if self.showResult:print (\"Draw Game\")\n",
    "                    elif self.board.winner == self.player_turn.myturn:\n",
    "                        out = \"Winner : \" + self.player_turn.name\n",
    "                        if self.showResult: print(out)\n",
    "                    else:\n",
    "                        print (\"Invalid Move!\")\n",
    "                    self.nwon[self.board.winner]+=1\n",
    "                else:\n",
    "                    self.switch_player()\n",
    "                    #Notice other player that the game is going\n",
    "                    self.player_turn.getGameResult(self.board)\n",
    "\n",
    "            self.nplayed+=1\n",
    "            if self.nplayed%self.stat==0 or self.nplayed==self.nplay:\n",
    "                print(self.player_x.name+\":\"+str(self.nwon[self.player_x.myturn])+\",\"+self.player_o.name+\":\"+str(self.nwon[self.player_o.myturn])\n",
    "                      +\",DRAW:\"+str(self.nwon[DRAW]))\n",
    "\n",
    "\n",
    "    def switch_player(self):\n",
    "        if self.player_turn == self.player_x:\n",
    "            self.player_turn=self.player_o\n",
    "        else:\n",
    "            self.player_turn=self.player_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# プレイヤーの作成\n",
    "# ランダム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class PlayerRandom:\n",
    "    def __init__(self,turn):\n",
    "        self.name=\"Random\"\n",
    "        self.myturn=turn\n",
    "\n",
    "    def act(self,board):\n",
    "        acts=board.get_possible_pos()\n",
    "        i=random.randrange(len(acts))\n",
    "        return acts[i]\n",
    "\n",
    "\n",
    "    def getGameResult(self,board):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 強化版ランダム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PlayerAlphaRandom:\n",
    "\n",
    "\n",
    "    def __init__(self,turn,name=\"AlphaRandom\"):\n",
    "        self.name=name\n",
    "        self.myturn=turn\n",
    "\n",
    "    def getGameResult(self,winner):\n",
    "        pass\n",
    "\n",
    "    def act(self,board):\n",
    "        acts=board.get_possible_pos()\n",
    "        #see only next winnable act\n",
    "        for act in acts:\n",
    "            tempboard=board.clone()\n",
    "            tempboard.move(act,self.myturn)\n",
    "            # check if win\n",
    "            if tempboard.winner==self.myturn:\n",
    "                #print (\"Check mate\")\n",
    "                return act\n",
    "        i=random.randrange(len(acts))\n",
    "        return acts[i]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 人間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PlayerHuman:\n",
    "    def __init__(self,turn):\n",
    "        self.name=\"Human\"\n",
    "        self.myturn=turn\n",
    "\n",
    "    def act(self,board):\n",
    "        valid = False\n",
    "        while not valid:\n",
    "            try:\n",
    "                act = input(\"Where would you like to place \" + str(self.myturn) + \" (1-9)? \")\n",
    "                act = int(act)\n",
    "                #if act >= 1 and act <= 9 and board.board[act-1]==EMPTY:\n",
    "                if act >= 1 and act <= 9:\n",
    "                    valid=True\n",
    "                    return act-1\n",
    "                else:\n",
    "                    print (\"That is not a valid move! Please try again.\")\n",
    "            except Exception as e:\n",
    "                    print (act +  \"is not a valid move! Please try again.\")\n",
    "        return act\n",
    "\n",
    "    def getGameResult(self,board):\n",
    "        if board.winner is not None and board.winner!=self.myturn and board.winner!=DRAW:\n",
    "            print(\"I lost...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PlayerMC:\n",
    "    def __init__(self,turn,name=\"MC\"):\n",
    "        self.name=name\n",
    "        self.myturn=turn\n",
    "\n",
    "    def getGameResult(self,winner):\n",
    "        pass\n",
    "\n",
    "    def win_or_rand(self,board,turn):\n",
    "        acts=board.get_possible_pos()\n",
    "        #see only next winnable act\n",
    "        for act in acts:\n",
    "            tempboard=board.clone()\n",
    "            tempboard.move(act,turn)\n",
    "            # check if win\n",
    "            if tempboard.winner==turn:\n",
    "                return act\n",
    "        i=random.randrange(len(acts))\n",
    "        return acts[i]\n",
    "\n",
    "    def trial(self,score,board,act):\n",
    "        tempboard=board.clone()\n",
    "        tempboard.move(act,self.myturn)\n",
    "        tempturn=self.myturn\n",
    "        while tempboard.winner is None:\n",
    "            tempturn=tempturn*-1\n",
    "            tempboard.move(self.win_or_rand(tempboard,tempturn),tempturn)\n",
    "\n",
    "        if tempboard.winner==self.myturn:\n",
    "            score[act]+=1\n",
    "        elif tempboard.winner==DRAW:\n",
    "            pass\n",
    "        else:\n",
    "            score[act]-=1\n",
    "\n",
    "\n",
    "    def getGameResult(self,board):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def act(self,board):\n",
    "        acts=board.get_possible_pos()\n",
    "        scores={}\n",
    "        n=50\n",
    "        for act in acts:\n",
    "            scores[act]=0\n",
    "            for i in range(n):\n",
    "                #print(\"Try\"+str(i))\n",
    "                self.trial(scores,board,act)\n",
    "\n",
    "            #print(scores)\n",
    "            scores[act]/=n\n",
    "\n",
    "        max_score=max(scores.values())\n",
    "        for act, v in scores.items():\n",
    "            if v == max_score:\n",
    "                #print(str(act)+\"=\"+str(v))\n",
    "                return act\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PlayerQL:\n",
    "    def __init__(self,turn,name=\"QL\",e=0.2,alpha=0.3):\n",
    "        self.name=name\n",
    "        self.myturn=turn\n",
    "        self.q={} #set of s,a\n",
    "        self.e=e\n",
    "        self.alpha=alpha\n",
    "        self.gamma=0.9\n",
    "        self.last_move=None\n",
    "        self.last_board=None\n",
    "        self.totalgamecount=0\n",
    "\n",
    "\n",
    "    def policy(self,board):\n",
    "        self.last_board=board.clone()\n",
    "        acts=board.get_possible_pos()\n",
    "        #Explore sometimes\n",
    "        if random.random() < (self.e/(self.totalgamecount//10000+1)):\n",
    "                i=random.randrange(len(acts))\n",
    "                return acts[i]\n",
    "        qs = [self.getQ(tuple(self.last_board.board),act) for act in acts]\n",
    "        maxQ= max(qs)\n",
    "\n",
    "        if qs.count(maxQ) > 1:\n",
    "            # more than 1 best option; choose among them randomly\n",
    "            best_options = [i for i in range(len(acts)) if qs[i] == maxQ]\n",
    "            i = random.choice(best_options)\n",
    "        else:\n",
    "            i = qs.index(maxQ)\n",
    "\n",
    "        self.last_move = acts[i]\n",
    "        return acts[i]\n",
    "\n",
    "    def getQ(self, state, act):\n",
    "        # encourage exploration; \"optimistic\" 1.0 initial values\n",
    "        if self.q.get((state, act)) is None:\n",
    "            self.q[(state, act)] = 1\n",
    "        return self.q.get((state, act))\n",
    "\n",
    "    def getGameResult(self,board):\n",
    "        r=0\n",
    "        if self.last_move is not None:\n",
    "            if board.winner is None:\n",
    "                self.learn(self.last_board,self.last_move, 0, board)\n",
    "                pass\n",
    "            else:\n",
    "                if board.winner == self.myturn:\n",
    "                    self.learn(self.last_board,self.last_move, 1, board)\n",
    "                elif board.winner !=DRAW:\n",
    "                    self.learn(self.last_board,self.last_move, -1, board)\n",
    "                else:\n",
    "                    self.learn(self.last_board,self.last_move, 0, board)\n",
    "                self.totalgamecount+=1\n",
    "                self.last_move=None\n",
    "                self.last_board=None\n",
    "\n",
    "    def learn(self,s,a,r,fs):\n",
    "        pQ=self.getQ(tuple(s.board),a)\n",
    "        if fs.winner is not None:\n",
    "            maxQnew=0\n",
    "        else:\n",
    "            maxQnew=max([self.getQ(tuple(fs.board),act) for act in fs.get_possible_pos()])\n",
    "        self.q[(tuple(s.board),a)]=pQ+self.alpha*((r+self.gamma*maxQnew)-pQ)\n",
    "        #print (str(s.board)+\"with \"+str(a)+\" is updated from \"+str(pQ)+\" refs MAXQ=\"+str(maxQnew)+\":\"+str(r))\n",
    "        #print(self.q)\n",
    "\n",
    "\n",
    "    def act(self,board):\n",
    "        return self.policy(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ゲームプレイ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Human_vs_Random():\n",
    "    p1=PlayerHuman(PLAYER_X)\n",
    "    p2 = PlayerAlphaRandom(PLAYER_O)\n",
    "    game=TTT_GameOrganizer(p1,p2)\n",
    "    game.progress()\n",
    "\n",
    "def MC_vs_Human():\n",
    "    p1 = PlayerMC(PLAYER_X,\"M1\")\n",
    "    p2 = PlayerMC(PLAYER_O,\"M2\")\n",
    "    game = TTT_GameOrganizer(p1,p2,100,False)\n",
    "    game.progress()\n",
    "    p1 = PlayerHuman(PLAYER_X)\n",
    "    game=TTT_GameOrganizer(p1,p2)\n",
    "    game.progress()\n",
    "    \n",
    "def Q_learning_vs_Q_learning():\n",
    "    pQ=PlayerQL(PLAYER_O,\"QL1\")\n",
    "    p2=PlayerQL(PLAYER_X,\"QL2\")\n",
    "    game=TTT_GameOrganizer(pQ,p2,100000,False,False,10000)\n",
    "    game.progress()\n",
    "    \n",
    "def Q_learning_vs_Human():\n",
    "    pQ=PlayerQL(PLAYER_O,\"QL1\")\n",
    "    p2=PlayerQL(PLAYER_X,\"QL2\")\n",
    "    game=TTT_GameOrganizer(pQ,p2,100000,False,False,100000)\n",
    "    game.progress()\n",
    "    pQ.e=0\n",
    "    p2=PlayerMC(PLAYER_X,\"M1\")\n",
    "    game=TTT_GameOrganizer(pQ,p2,100,False,False,100)\n",
    "    game.progress()\n",
    "    p2=PlayerHuman(PLAYER_X)\n",
    "    game=TTT_GameOrganizer(pQ,p2,2)\n",
    "    game.progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QL1:17089,QL2:17008,DRAW:65903\n",
      "QL1:21,M1:0,DRAW:79\n",
      "Turn is Human\n",
      "Where would you like to place 1 (1-9)? 5\n",
      "   |   |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is QL1\n",
      "   |   |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      " O |   |   \n",
      "Turn is Human\n",
      "Where would you like to place 1 (1-9)? 1\n",
      " X |   |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      " O |   |   \n",
      "Turn is QL1\n",
      " X |   |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      " O |   | O \n",
      "Turn is Human\n",
      "Where would you like to place 1 (1-9)? 8\n",
      " X |   |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      " O | X | O \n",
      "Turn is QL1\n",
      " X | O |   \n",
      "-----------\n",
      "   | X |   \n",
      "-----------\n",
      " O | X | O \n",
      "Turn is Human\n",
      "Where would you like to place 1 (1-9)? 4\n",
      " X | O |   \n",
      "-----------\n",
      " X | X |   \n",
      "-----------\n",
      " O | X | O \n",
      "Turn is QL1\n",
      " X | O |   \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      " O | X | O \n",
      "Turn is Human\n",
      "Where would you like to place 1 (1-9)? 3\n",
      " X | O | X \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      " O | X | O \n",
      "Draw Game\n",
      "Turn is Human\n",
      "Where would you like to place 1 (1-9)? 4\n",
      "   |   |   \n",
      "-----------\n",
      " X |   |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is QL1\n",
      " O |   |   \n",
      "-----------\n",
      " X |   |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is Human\n",
      "Where would you like to place 1 (1-9)? 5\n",
      " O |   |   \n",
      "-----------\n",
      " X | X |   \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is QL1\n",
      " O |   |   \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is Human\n",
      "Where would you like to place 1 (1-9)? 3\n",
      " O |   | X \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      "   |   |   \n",
      "Turn is QL1\n",
      " O |   | X \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      " O |   |   \n",
      "Turn is Human\n",
      "Where would you like to place 1 (1-9)? 8\n",
      " O |   | X \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      " O | X |   \n",
      "Turn is QL1\n",
      " O | O | X \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      " O | X |   \n",
      "Turn is Human\n",
      "Where would you like to place 1 (1-9)? 9\n",
      " O | O | X \n",
      "-----------\n",
      " X | X | O \n",
      "-----------\n",
      " O | X | X \n",
      "Draw Game\n",
      "QL1:0,Human:0,DRAW:2\n"
     ]
    }
   ],
   "source": [
    "#Human_vs_Random()\n",
    "Q_learning_vs_Human()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN(Deep Q Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "\n",
    "from chainer import Function, gradient_check, Variable, optimizers, serializers, utils\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import numpy as np\n",
    "from chainer import computational_graph as c\n",
    "\n",
    "# Network definition\n",
    "class MLP(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_in, n_units, n_out):\n",
    "        super(MLP, self).__init__(\n",
    "            l1=L.Linear(n_in, n_units),  # first layer\n",
    "            l2=L.Linear(n_units, n_units),  # second layer\n",
    "            l3=L.Linear(n_units, n_units),  # Third layer\n",
    "            l4=L.Linear(n_units, n_out),  # output layer\n",
    "        )\n",
    "\n",
    "    def __call__(self, x, t=None, train=False):\n",
    "        h = F.leaky_relu(self.l1(x))\n",
    "        h = F.leaky_relu(self.l2(h))\n",
    "        h = F.leaky_relu(self.l3(h))\n",
    "        h = self.l4(h)\n",
    "\n",
    "        if train:\n",
    "            return F.mean_squared_error(h,t)\n",
    "        else:\n",
    "            return h\n",
    "\n",
    "    def get(self,x):\n",
    "        # input x as float, output float\n",
    "        return self.predict(Variable(np.array([x]).astype(np.float32).reshape(1,1))).data[0][0]\n",
    "\n",
    "\n",
    "class DQNPlayer:\n",
    "    def __init__(self, turn,name=\"DQN\",e=1,dispPred=False):\n",
    "        self.name=name\n",
    "        self.myturn=turn\n",
    "        self.model = MLP(9, 162,9)\n",
    "        self.optimizer = optimizers.SGD()\n",
    "        self.optimizer.setup(self.model)\n",
    "        self.e=e\n",
    "        self.gamma=0.95\n",
    "        self.dispPred=dispPred\n",
    "        self.last_move=None\n",
    "        self.last_board=None\n",
    "        self.last_pred=None\n",
    "        self.totalgamecount=0\n",
    "        self.rwin,self.rlose,self.rdraw,self.rmiss=1,-1,0,-1.5\n",
    "\n",
    "\n",
    "    def act(self,board):\n",
    "\n",
    "        self.last_board=board.clone()\n",
    "        x=np.array([board.board],dtype=np.float32).astype(np.float32)\n",
    "\n",
    "        pred=self.model(x)\n",
    "        if self.dispPred:print(pred.data)\n",
    "        self.last_pred=pred.data[0,:]\n",
    "        act=np.argmax(pred.data,axis=1)\n",
    "        if self.e > 0.2: #decrement epsilon over time\n",
    "            self.e -= 1/(20000)\n",
    "        if random.random() < self.e:\n",
    "            acts=board.get_possible_pos()\n",
    "            i=random.randrange(len(acts))\n",
    "            act=acts[i]\n",
    "        i=0\n",
    "        if type(act) != int:\n",
    "            act = int(act)\n",
    "        val = board.board[act]\n",
    "        while val!=EMPTY:\n",
    "            #print(\"Wrong Act \"+str(board.board)+\" with \"+str(act))\n",
    "            self.learn(self.last_board,act, -1, self.last_board)\n",
    "            x=np.array([board.board],dtype=np.float32).astype(np.float32)\n",
    "            pred=self.model(x)\n",
    "            #print(pred.data)\n",
    "            act=np.argmax(pred.data,axis=1)\n",
    "            i+=1\n",
    "            if i>10:\n",
    "                #print(\"Exceed Pos Find\"+str(board.board)+\" with \"+str(act))\n",
    "                acts=self.last_board.get_possible_pos()\n",
    "                act=acts[random.randrange(len(acts))]\n",
    "\n",
    "        self.last_move=act\n",
    "        #self.last_pred=pred.data[0,:]\n",
    "        return act\n",
    "\n",
    "    def getGameResult(self,board):\n",
    "        r=0\n",
    "        if self.last_move is not None:\n",
    "            if board.winner is None:\n",
    "                self.learn(self.last_board,self.last_move, 0, board)\n",
    "                pass\n",
    "            else:\n",
    "                if board.board== self.last_board.board:            \n",
    "                    self.learn(self.last_board,self.last_move, self.rmiss, board)\n",
    "                elif board.winner == self.myturn:\n",
    "                    self.learn(self.last_board,self.last_move, self.rwin, board)\n",
    "                elif board.winner !=DRAW:\n",
    "                    self.learn(self.last_board,self.last_move, self.rlose, board)\n",
    "                else:                    #DRAW\n",
    "                    self.learn(self.last_board,self.last_move, self.rdraw, board)\n",
    "                self.totalgamecount+=1\n",
    "                self.last_move=None\n",
    "                self.last_board=None\n",
    "                self.last_pred=None\n",
    "\n",
    "    def learn(self,s,a,r,fs):\n",
    "        if fs.winner is not None:\n",
    "            maxQnew=0\n",
    "        else:\n",
    "            x=np.array([fs.board],dtype=np.float32).astype(np.float32)\n",
    "            maxQnew=np.max(self.model(x).data[0])\n",
    "        update=r+self.gamma*maxQnew\n",
    "        #print(('Prev Board:{} ,ACT:{}, Next Board:{}, Get Reward {}, Update {}').format(s.board,a,fs.board,r,update))\n",
    "        #print(('PREV:{}').format(self.last_pred))\n",
    "        self.last_pred[a]=update\n",
    "\n",
    "        x=np.array([s.board],dtype=np.float32).astype(np.float32)\n",
    "        t=np.array([self.last_pred],dtype=np.float32).astype(np.float32)\n",
    "        self.model.zerograds()\n",
    "        loss=self.model(x,t,train=True)\n",
    "        loss.backward()\n",
    "        self.optimizer.update()\n",
    "        #print(('Updated:{}').format(self.model(x).data))\n",
    "        #print (str(s.board)+\"with \"+str(a)+\" is updated from \"+str(pQ)+\" refs MAXQ=\"+str(maxQnew)+\":\"+str(r))\n",
    "        #print(self.q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DQN_vs_Human():\n",
    "    print(\"VS Random\")\n",
    "    pDQ=DQNPlayer(PLAYER_X)\n",
    "    p2=PlayerAlphaRandom(PLAYER_O)\n",
    "    game=TTT_GameOrganizer(pDQ,p2,150,False,False,50)\n",
    "    game.progress()\n",
    "    pQ=PlayerQL(PLAYER_O,\"QL1\")\n",
    "    p2=PlayerQL(PLAYER_X,\"QL2\")\n",
    "    game=TTT_GameOrganizer(pQ,p2,100000,False,False,100000)\n",
    "    game.progress()\n",
    "    pQ.e=0\n",
    "    p2=PlayerMC(PLAYER_X,\"M1\")\n",
    "    game=TTT_GameOrganizer(pQ,p2,100,False,False,100)\n",
    "    game.progress()\n",
    "    print(\"VS Q-learning\")\n",
    "    pDQ.e = 0\n",
    "    game = TTT_GameOrganizer(pDQ,pQ,150,False,False,10)\n",
    "    game.progress()\n",
    "    print(\"VS Human\")\n",
    "    pDQ.e = 0\n",
    "    p2 = PlayerHuman(PLAYER_O)\n",
    "    game = TTT_GameOrganizer(pDQ,p2,2)\n",
    "    game.progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DQN_vs_Human()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
